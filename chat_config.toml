[chat_completion]
active_model = "llama3"
base_url = "http://localhost:11434"

[configured_models]
large_language_models = [ "llama3", "gemma:7b", "deepseek-coder-v2:latest", "test",]
